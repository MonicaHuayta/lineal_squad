##Pregunta 4
El conjunto de datos coleman contiene informaciÃ³n sobre 20 escuelas de los estados de Mid- Atlantic y New England, extraÃ­das de una poblaciÃ³n estudiada por Coleman et al. (1966). Mosteller y Tukey (1977) analizan esta muestra que consiste en mediciones de las siguientes seis variables.
salaryP: salarios del personal por alumno
fatherWc: porcentaje de padres con trabajo administrativo
sstatus: desviaciÃ³n compuesta del estado socioeconÃ³mico: significa para el tamaÃ±o de la familia, la integridad de la familia, la educaciÃ³n del padre, la educaciÃ³n de la madre y los artÃ­culos del hogar
teacherSc: puntuaciÃ³n media de la prueba verbal del maestro
motherLev: nivel educativo medio de la madre, una unidad equivale a dos aÃ±os escolares
Y: puntaje de la prueba verbal promedio (variable respuesta)

####a) Ajuste un modelo de regresiÃ³n por mÃ­nimos cuadrados ordinarios e identifique las observaciones atÃ­picas y reajuste el modelo de regresiÃ³n eliminando las observaciones identificadas. Interprete los resultados.

```{r MCO}
library(robustbase)
data("coleman")
coleman
# Estimando por MÃ¬nimos Cuadrados Ordinarios (MCO) con todas las variables
MCO = lm(Y ~., data = coleman)
summary(MCO)

# Graficamente 
plot(coleman$Y, MCO$fitted.values)+
abline(a=0,b=1, col="red")

plot(coleman$Y, MCO$residuals)+
abline(a=0,b=0, col="red")
# se observan outliers

# Test de heterocedasticidad
rstandard(MCO)
library(car)
ncvTest(MCO) # Presencia de heterocedasticidad

# Identificando los outliers
plot(cooks.distance(MCO)) 

# considerando un mÃ ximo de 4/n para eliminar los outliers
indices.cook <- which(cooks.distance(MCO) >= 4/nrow(coleman))
coleman <- coleman[-indices.cook, ]

# ajustando sin outliers
MCO2 <- lm(formula = Y ~ ., data = coleman)
summary(MCO2)
```

## Interpretando los Resultados
Observando los resultados con $MCO$ como primer modelo de regresiÃ³n del cuadro de summary(MCO) se extrae que solo una variable (sstatus) se muestra estadÃ­sticamente significativo, mientras que el ajuste del modelo parece sugerir un buen ajuste con (Multiple R-squared:  0.9063,	Adjusted R-squared:  0.8728).
Haciendo un anÃ¡lisis grÃ¡fico, se pudo observar presencia de valores atipicos confirmando con la prueba de $ncvTest(MCO)$ indicando presencia de heterocedasticidad, luego procediendo a eliminar los outliers y reajustando el modelo, se observan los resultados con $MCO2$ donde se observa una mejora del modelo con variables estadÃ­sticamente significativas y una mejora en el ajuste del modelo con (Multiple R-squared:  0.9633,	Adjusted R-squared:  0.9492).

####b) Ajuste un modelo de regresiÃ³n robusta con las funciones objetivo hechas en clase y compare los resultados con el modelo del Ã­tem a).

Utilizando los procedimientos realizados en clases vamos a usar el estimador-M de Huber para el modelo de regresiÃ³n de Duncan, utilizando la funciÃ³n `rlm` (modelo lineal robusto):

```{r, regresion de regresiÃ³n robusto} 
library(MASS) 
mod.robusto <- rlm(Y ~ ., data = coleman)
summary(mod.robusto)
```

Observando los resultados obtenidos para la estimaciÃ³n de los parÃ¡metros, se puede indicar que la estimaciÃ³n obtenida mediante el modelo $mod.robusto$ se encuentran entre las estimaciones obtenidas mediante los ajustes con mÃ­nimos cuadrados $MCO$(con datos completos) y $MCO2$(sin datos atipicos).

En seguida extraemos y graficamos los pesos finales utilizados en el ajuste de $mod.robusto$. 

```{r, }
#windows()
plot(mod.robusto$w, ylab="Huber Weight")
smallweights <- which(mod.robusto$w < 0.8)
showLabels(1:45, mod.robusto$w, rownames(coleman), method=smallweights, cex.=.6)
```
Observando el grÃ¡fico y etiquetando las observaciones con pesos inferiores a $0.8$, se puede indicar que las escuelas 3, 17 y 19 se comportan como outliers o valores atÃ­picos.

Adicionalmente, la funciÃ³n $rlm$ segÃºn lo indicado en las clases, tambiÃ©n puede ajustar el modelo usando el estimador $bisquare$, especificando el argumento $method ="MM"$ la funciÃ³n $rlm$ solicita estimadores bisquare con valores iniciales determinados por una regresiÃ³n preliminar de influencia acotada. Como se indica a continuaciÃ³n:

```{r,}
mod.bisquare <- rlm(Y ~., data=coleman, method="MM")
summary(mod.bisquare)
```

Comparando los parÃ¡metros estimados con el $mod.robusto$ (mÃ©todo de Huber), los coeficientes obtenidos con el modelo $mod.bisquare$ son mayores en todas las variables, grÃ¡ficamente se tiene:

```{r}
#windows()
plot(mod.bisquare$w, ylab="Bisquare Weight")
showLabels(1:45, mod.bisquare$w, rownames(coleman),method= which(mod.bisquare$w < 0.8), cex.=0.6)
```
Con la estimaciÃ³n $bisquare$ se puede decir que, la Ãºnica observaciÃ³n que se comporta valor atipico es el de la escuela $3$, coencidiendo con el $mod.robusto$ pero excluyendo a las escuelas $17$ y $19$.

## Comparando resultados 
En general se puede comentar que, las estimaciones obtenidas mediante mÃ­nimos cuadrados indican valores extremos, con $MCO$ valores mÃ­nimos y con $MCO2$ valores mÃ¡ximos, mientras que las estimaciones obtenidas con regresiÃ³n robusta indican valores intermedios, casÃ­ para toda las variables excepto para $teacherSc$ donde los valores con regresiÃ³n robusta son mayores a los obtenidos con mÃ­nimos cuadrados.
